{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3ead2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "!pip install torch transformers sentence-transformers faiss-cpu accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149180f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#GPU\n",
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021183fe",
   "metadata": {},
   "source": [
    "# 1. DATA PREPROCESSING + CLAUSE-AWARE CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839f425",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove formatting artefacts but preserve clause numbering.\n",
    "    \"\"\"\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove page numbers if any (customise if needed)\n",
    "    text = re.sub(r'\\b\\d+\\s*DEC\\s*2025\\b', '', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clause_aware_chunking(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Split document by Regulation and clause markers.\n",
    "    Returns structured chunks with metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    # Split by main Regulation numbers (1. Scope, 2. Entitlement, etc.)\n",
    "    regulation_pattern = r'(?=\\n?\\s*\\d+\\.\\s)'\n",
    "    regulations = re.split(regulation_pattern, text)\n",
    "\n",
    "    for reg in regulations:\n",
    "        reg = reg.strip()\n",
    "        if not reg:\n",
    "            continue\n",
    "\n",
    "        # Extract regulation number\n",
    "        reg_match = re.match(r'(\\d+)\\.', reg)\n",
    "        if not reg_match:\n",
    "            continue\n",
    "\n",
    "        reg_number = reg_match.group(1)\n",
    "\n",
    "        # Split clauses (i), (ii), (iii)\n",
    "        clause_pattern = r'(?=\\(\\w+\\))'\n",
    "        clauses = re.split(clause_pattern, reg)\n",
    "\n",
    "        for clause in clauses:\n",
    "            clause = clause.strip()\n",
    "            if len(clause) < 50:  # ignore tiny fragments\n",
    "                continue\n",
    "\n",
    "            clause_id_match = re.match(r'\\((\\w+)\\)', clause)\n",
    "            clause_id = clause_id_match.group(1) if clause_id_match else \"main\"\n",
    "\n",
    "            chunks.append({\n",
    "                \"regulation\": reg_number,\n",
    "                \"clause\": clause_id,\n",
    "                \"text\": clause.strip()\n",
    "            })\n",
    "\n",
    "    return chunks\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
